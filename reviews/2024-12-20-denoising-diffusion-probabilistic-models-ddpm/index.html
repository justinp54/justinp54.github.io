<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> [논문리뷰] Denoising Diffusion Probabilistic Models (DDPM) | Junsang Park </title> <meta name="author" content="Junsang Park"> <meta name="description" content="DDPM 논문을 공부하면서 정리한 annotated reading note입니다."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://justinp54.github.io/reviews/2024-12-20-denoising-diffusion-probabilistic-models-ddpm/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Junsang</span> Park </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/reviews/">Paper Reviews <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Journal </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <style>.post-header h1.post-title{font-size:1.75rem!important;font-weight:600!important;margin-bottom:.5rem}.post-content:not(.paper-review) h1{font-size:1.75rem!important;font-weight:600!important;margin-top:2rem;margin-bottom:1rem}.post-content:not(.paper-review) h2{font-size:1.5rem!important;font-weight:600!important;margin-top:1.5rem;margin-bottom:.75rem}.post-content:not(.paper-review) h3{font-size:1.25rem!important;font-weight:500!important;margin-top:1.25rem;margin-bottom:.5rem}</style> <div class="post"> <header class="post-header"> <h1 class="post-title">[논문리뷰] Denoising Diffusion Probabilistic Models (DDPM)</h1> <p class="post-meta"> Created on December 20, 2024 </p> <p class="post-tags"> <a href="/reviews/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/reviews/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/reviews/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/reviews/tag/generative-models"> <i class="fa-solid fa-hashtag fa-sm"></i> generative-models</a>   <a href="/reviews/tag/diffusion-models"> <i class="fa-solid fa-hashtag fa-sm"></i> diffusion-models</a>   <a href="/reviews/tag/review"> <i class="fa-solid fa-hashtag fa-sm"></i> review</a>   ·   <a href="/reviews/category/paper-review"> <i class="fa-solid fa-tag fa-sm"></i> paper-review</a> </p> </header> <article class="post-content paper-review"> <div id="table-of-contents" class="paper-review-toc"> <h3>Contents</h3> </div> <hr> <div id="markdown-content"> <div class="paper-info-block"> <p><strong>NeurIPS 2020.</strong></p> <p><strong>Jonathan Ho, Ajay Jain, Pieter Abbeel</strong></p> <p><strong>UC Berkeley</strong></p> <p><a href="https://arxiv.org/abs/2006.11239" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://github.com/hojonathanho/diffusion" rel="external nofollow noopener" target="_blank">[Github]</a></p> <p><strong>19 Jun 2020</strong></p> </div> <h1 id="introduction">Introduction</h1> <p>Denoising Diffusion Probabilistic Models (DDPM)는 최근 생성 모델 분야에서 혁신적인 성과를 보여준 논문입니다. 이 논문은 <strong>확률적 생성 모델</strong>의 새로운 접근 방식을 제시하며, 고품질 이미지 생성에서 뛰어난 성능을 달성했습니다.</p> <p>DDPM의 핵심 아이디어는 간단합니다: <strong>순수한 노이즈에서 시작하여 점진적으로 노이즈를 제거하여 데이터를 생성</strong>하는 것입니다. 이는 기존의 GAN이나 VAE와는 완전히 다른 접근 방식입니다.</p> <h2 id="key-contributions">Key Contributions</h2> <p>이 논문의 주요 기여는 다음과 같습니다:</p> <h1 id="notation">Notation</h1> <p>논문에서 사용하는 주요 기호와 변수:</p> <ul> <li>\(x_0\): 원본 데이터 (clean image)</li> <li>\(x_t\): 시간 단계 \(t\)에서의 데이터 (\(t = 1, 2, \ldots, T\))</li> <li>\(T\): Forward process의 총 시간 단계 수 (일반적으로 1000)</li> <li>\(\beta_t\): 시간 단계 \(t\)에서의 노이즈 스케줄 (noise schedule)</li> <li>\(\alpha_t = 1 - \beta_t\): 노이즈를 제거하는 비율</li> <li>\(\bar{\alpha}_t = \prod_{s=1}^t \alpha_s\): 누적 곱</li> <li>\(\epsilon\): 가우시안 노이즈 \(\epsilon \sim \mathcal{N}(0, I)\)</li> <li>\(\epsilon_\theta(x_t, t)\): 신경망이 예측하는 노이즈</li> <li>\(q(\cdot)\): Forward process의 분포</li> <li>\(p_\theta(\cdot)\): Reverse process의 파라미터화된 분포</li> </ul> <h2 id="methodology">Methodology</h2> <hr> <h1 id="forward-diffusion-process">Forward Diffusion Process</h1> <p>Forward process는 데이터 \(x_0\)에 점진적으로 가우시안 노이즈를 추가하여, 최종적으로 순수한 노이즈 \(x_T \sim \mathcal{N}(0, I)\)로 만드는 과정입니다.</p> <h2 id="정의">정의</h2> <p>각 시간 단계에서의 전이 분포는 다음과 같이 정의됩니다:</p> \[q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)\] <p>여기서 \(\beta_t\)는 각 시간 단계에서 추가되는 노이즈의 양을 결정하는 스케줄입니다.</p> <h2 id="중요한-성질-임의의-시간-단계로-직접-점프">중요한 성질: 임의의 시간 단계로 직접 점프</h2> <p>논문의 핵심은, 이 과정을 반복하지 않고도 임의의 시간 단계 \(t\)에서의 샘플을 직접 계산할 수 있다는 것입니다:</p> \[q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t) I)\] <p>여기서 \(\bar{\alpha}_t = \prod_{s=1}^t (1-\beta_s)\)입니다.</p> <h3 id="reverse-denoising-process">Reverse Denoising Process</h3> <p><strong>다음 섹션에서의 사용</strong>: 이 수식은 Training objective에서 \(x_t\)를 샘플링할 때 사용됩니다. \(x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon\) 형태로 직접 계산됩니다.</p> <hr> <h1 id="reverse-denoising-process-1">Reverse Denoising Process</h1> <p>Reverse process는 노이즈 \(x_T \sim \mathcal{N}(0, I)\)에서 시작하여, 점진적으로 노이즈를 제거하여 원본 데이터 \(x_0\)를 복원하는 과정입니다.</p> <h2 id="정의-1">정의</h2> <p>Reverse process는 다음의 파라미터화된 분포로 근사됩니다:</p> \[p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))\] <p>여기서 \(\mu_\theta\)와 \(\Sigma_\theta\)는 신경망으로 학습되는 파라미터입니다.</p> <p><strong>읽기 포인트</strong>: Forward process는 고정된 분포이지만, Reverse process는 학습 가능한 파라미터 \(\theta\)를 가집니다. 신경망은 주어진 \(x_t\)와 시간 단계 \(t\)를 입력받아, 이전 단계의 데이터 \(x_{t-1}\)의 평균과 분산을 예측합니다.</p> <p><strong>다음 섹션에서의 사용</strong>: Training objective에서 \(\mu_\theta\)를 직접 학습하는 대신, 노이즈 \(\epsilon\)을 예측하는 방식으로 단순화됩니다.</p> <hr> <h1 id="training-objective">Training Objective</h1> <p>학습 목표는 각 시간 단계 \(t\)에서 노이즈 \(\epsilon\)을 예측하는 것입니다.</p> <h2 id="loss-function">Loss Function</h2> \[L = \mathbb{E}_{t, x_0, \epsilon} \left[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \right]\] <p>여기서:</p> <ul> <li>\(t\)는 \(\{1, 2, \ldots, T\}\)에서 균등하게 샘플링</li> <li>\(\epsilon \sim \mathcal{N}(0, I)\)는 랜덤 노이즈</li> <li>\(x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon\)는 Forward process 수식을 사용하여 계산</li> </ul> <table> <tbody> <tr> <td> <strong>읽기 포인트</strong>: 이 loss가 등장하는 이유는, 원래의 reverse process 분포 $$p_\theta(x_{t-1}</td> <td>x_t)$$를 직접 학습하는 것보다 노이즈를 예측하는 것이 더 단순하고 안정적이기 때문입니다. 논문에서는 이 loss가 실제로 reverse process의 log-likelihood를 최대화하는 것과 관련이 있음을 보여줍니다.</td> </tr> </tbody> </table> <h2 id="experimental-results">Experimental Results</h2> <hr> <h1 id="training-algorithm">Training Algorithm</h1> <figure class="paper-figure"> <img src="/assets/img/papers/ddpm/algorithm1-training.png" alt="DDPM Training Algorithm"> <figcaption> <strong>Algorithm 1: Training</strong> </figcaption> </figure> <h2 id="how-to-read-this-algorithm">How to Read This Algorithm</h2> <p>다음 표는 다양한 생성 모델과의 성능 비교를 보여줍니다:</p> <ul> <li> <strong>Line 1</strong>: 데이터셋에서 샘플 \(x_0\)를 선택합니다. 이것이 학습할 원본 이미지입니다.</li> <li> <strong>Line 2</strong>: 시간 단계 \(t\)를 \(\{1, 2, \ldots, T\}\)에서 균등하게 랜덤 선택합니다. Forward process의 임의의 단계에서 학습할 수 있게 해줍니다.</li> <li> <strong>Line 3</strong>: 노이즈 \(\epsilon \sim \mathcal{N}(0, I)\)를 샘플링합니다. 이 노이즈를 신경망이 예측해야 하는 목표입니다.</li> <li> <table> <tbody> <tr> <td> <strong>Line 4</strong>: Forward process 수식 $$q(x_t</td> <td>x_0)\(를 사용하여\)x_t$$를 직접 계산합니다. 반복적인 과정 없이 한 번에 계산할 수 있는 것이 핵심입니다.</td> </tr> </tbody> </table> </li> <li> <strong>Line 5</strong>: 신경망 \(\epsilon_\theta\)가 \(x_t\)와 \(t\)를 입력받아 노이즈를 예측합니다. 이는 Training objective에서 정의한 loss의 예측 부분입니다.</li> <li> <strong>Line 6</strong>: 예측된 노이즈 \(\epsilon_\theta(x_t, t)\)와 실제 노이즈 \(\epsilon\) 간의 MSE loss를 계산합니다. 이것이 논문의 수식 (14)에 해당합니다.</li> <li> <strong>Line 7</strong>: Loss를 역전파하여 신경망 파라미터 \(\theta\)를 업데이트합니다.</li> </ul> <p><strong>논문에서의 위치</strong>: 논문의 Section 3, Algorithm 1에 해당합니다.</p> <hr> <h1 id="sampling-algorithm">Sampling Algorithm</h1> <figure class="paper-figure"> <img src="/assets/img/papers/ddpm/algorithm2-sampling.png" alt="DDPM Sampling Algorithm"> <figcaption> <strong>Algorithm 2: Sampling</strong> </figcaption> </figure> <h2 id="how-to-read-this-algorithm-1">How to Read This Algorithm</h2> <p>이 알고리즘은 학습된 모델을 사용하여 새로운 샘플을 생성하는 과정입니다. Forward process를 역으로 수행합니다:</p> <ul> <li> <strong>Line 1</strong>: 순수한 가우시안 노이즈 \(x_T \sim \mathcal{N}(0, I)\)에서 시작합니다. Forward process의 최종 상태입니다.</li> <li> <strong>Line 2</strong>: \(T\)부터 1까지 역순으로 반복합니다. Reverse process를 단계적으로 수행합니다.</li> <li> <strong>Line 3</strong>: 만약 \(t &gt; 1\)이면 노이즈 \(z \sim \mathcal{N}(0, I)\)를 샘플링하고, \(t = 1\)이면 \(z = 0\)입니다. 마지막 단계에서는 확률적 노이즈를 추가하지 않습니다.</li> <li> <strong>Line 4</strong>: 신경망이 예측한 노이즈 \(\epsilon_\theta(x_t, t)\)를 사용합니다. Training algorithm에서 학습한 모델을 사용합니다.</li> <li> <strong>Line 5</strong>: Reverse process의 평균 \(\mu_\theta(x_t, t)\)를 계산합니다. 논문의 수식 (11)에 해당하며, 예측된 노이즈를 사용하여 계산됩니다.</li> <li> <strong>Line 6</strong>: 다음 단계의 샘플 \(x_{t-1}\)을 계산합니다. 평균 \(\mu_\theta(x_t, t)\)에 노이즈를 추가하여 샘플링합니다. 이것이 Reverse process의 샘플링 단계입니다.</li> </ul> <p><strong>논문에서의 위치</strong>: 논문의 Section 3.2, Algorithm 2에 해당합니다.</p> <hr> <h1 id="experimental-setup">Experimental Setup</h1> <p>논문에서는 다음과 같은 데이터셋에서 실험을 수행했습니다:</p> <ul> <li> <strong>CIFAR-10</strong>: 32×32 자연 이미지, 10개 클래스</li> <li> <strong>CelebA-HQ</strong>: 고해상도 얼굴 이미지 (256×256)</li> <li> <strong>LSUN</strong>: 대규모 자연 장면 이미지 (256×256, 512×512)</li> </ul> <h2 id="architecture-details">Architecture Details</h2> <figure class="paper-figure"> <img src="/assets/img/papers/ddpm/architecture-table.png" alt="DDPM Architecture Table"> <figcaption> <strong>Table: Model Architecture</strong> </figcaption> </figure> <h3 id="what-this-shows">What This Shows</h3> <p>이 표는 DDPM에서 사용하는 U-Net 아키텍처의 세부 사항을 보여줍니다. 주요 구성 요소:</p> <ul> <li> <strong>Time embedding</strong>: 시간 단계 \(t\)를 sinusoidal embedding으로 변환하여 네트워크에 주입합니다. 이는 네트워크가 현재 어느 단계에 있는지 알 수 있게 해줍니다.</li> <li> <strong>Attention mechanism</strong>: Self-attention을 사용하여 long-range dependencies를 모델링합니다.</li> <li> <strong>Residual connections</strong>: 깊은 네트워크에서의 gradient flow를 개선합니다.</li> </ul> <p><strong>논문에서의 위치</strong>: 논문의 Appendix B에 상세한 아키텍처 정보가 있습니다.</p> <hr> <h1 id="experimental-results-1">Experimental Results</h1> <h2 id="performance-comparison">Performance Comparison</h2> <figure class="paper-figure"> <img src="/assets/img/papers/ddpm/results-table.png" alt="DDPM Experimental Results Table"> <figcaption> <strong>Table: Quantitative Results</strong> </figcaption> </figure> <h3 id="what-this-shows-1">What This Shows</h3> <p>이 표는 DDPM과 다른 생성 모델들(GAN, VAE, Flow-based)의 성능을 비교합니다:</p> <ul> <li> <strong>FID (Fréchet Inception Distance)</strong>: 낮을수록 좋음. 생성된 이미지와 실제 이미지의 분포 간 거리를 측정합니다.</li> <li> <strong>IS (Inception Score)</strong>: 높을수록 좋음. 생성된 이미지의 품질과 다양성을 측정합니다.</li> </ul> <p><strong>논문에서의 위치</strong>: 논문의 Section 4에서 제시되는 주요 실험 결과입니다.</p> <h2 id="generated-samples">Generated Samples</h2> <figure class="paper-figure"> <img src="/assets/img/papers/ddpm/generated-samples.png" alt="DDPM Generated Samples"> <figcaption> <strong>Figure: Generated Samples</strong> </figcaption> </figure> <h3 id="what-this-shows-2">What This Shows</h3> <p>이 그림은 DDPM으로 생성된 샘플들을 보여줍니다. 논문에서는 다양한 데이터셋에서 고품질 이미지를 생성할 수 있음을 보여줍니다.</p> <p><strong>논문에서의 위치</strong>: 논문의 Section 4에 포함된 생성 샘플들입니다.</p> <hr> <h1 id="ablation-studies">Ablation Studies</h1> <p>논문에서는 여러 구성 요소의 중요성을 검증하기 위해 ablation study를 수행했습니다.</p> <h2 id="noise-schedule-comparison">Noise Schedule Comparison</h2> <figure class="paper-figure"> <img src="/assets/img/papers/ddpm/noise-schedule-comparison.png" alt="Noise Schedule Comparison"> <figcaption> <strong>Figure: Linear vs Cosine Schedule</strong> </figcaption> </figure> <h3 id="what-this-shows-3">What This Shows</h3> <p>이 그림은 linear schedule과 cosine schedule의 비교 결과를 보여줍니다:</p> <ul> <li> <strong>Linear schedule</strong>: \(\beta_t = \beta_1 + \frac{t-1}{T-1}(\beta_T - \beta_1)\)</li> <li> <strong>Cosine schedule</strong>: \(\bar{\alpha}_t = \frac{\cos((t/T + s)/(1+s) \cdot \pi/2)}{\cos(s \cdot \pi/2)}\)</li> </ul> <p>논문에서는 cosine schedule이 더 나은 성능을 보인다고 보고합니다.</p> <p><strong>논문에서의 위치</strong>: 논문의 Section 4.2에서 noise schedule에 대한 실험 결과입니다.</p> <hr> <h1 id="references">References</h1> <ol> <li> <strong>Ho, J., Jain, A., &amp; Abbeel, P.</strong> (2020). Denoising diffusion probabilistic models. <em>Advances in Neural Information Processing Systems</em>, 33.</li> </ol> <hr> <p><strong>Note</strong>: 이 노트는 논문을 읽으면서 정리한 내용입니다. 더 자세한 내용은 원본 논문을 참고하시기 바랍니다.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/plotly/">a post with plotly.js</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/photo-gallery/">a post with image galleries</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/tabs/">a post with tabs</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Junsang Park. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>